"""
ç®€åŒ–çš„æŸå¤±å‡½æ•°è°ƒåº¦å™¨ - ä¸“ç”¨äºå¾®è°ƒé˜¶æ®µçš„MSE+SSIMæƒé‡è°ƒæ•´
åŸºäºRMSEå€¼åŠ¨æ€è°ƒæ•´æƒé‡æ¯”ä¾‹ï¼Œä¼˜åŒ–æ¨¡å‹æ€§èƒ½
"""

import torch
import math
from typing import Dict, Optional
from enum import Enum


class ScheduleType(Enum):
    """è°ƒåº¦å™¨ç±»å‹æšä¸¾"""
    LINEAR = "linear"
    CONSTANT = "constant"
    RMSE_ADAPTIVE = "rmse_adaptive"


class LossWeightScheduler:
    """
    ç®€åŒ–çš„æŸå¤±æƒé‡è°ƒåº¦å™¨ - ä¸“ç”¨äºå¾®è°ƒé˜¶æ®µ
    
    åªæ”¯æŒMSEå’ŒSSIMä¸¤ä¸ªæŸå¤±çš„æƒé‡è°ƒåº¦ï¼Œ
    åŸºäºRMSEå€¼åŠ¨æ€è°ƒæ•´æƒé‡æ¯”ä¾‹
    """
    
    def __init__(self, 
                 total_epochs: int,
                 mse_weight: float = 1.0,
                 ssim_weight: float = 0.3,
                 adaptive_patience: int = 3,
                 adaptive_factor: float = 0.8,
                 verbose: bool = True):
        """
        Args:
            total_epochs: æ€»è®­ç»ƒè½®æ•°
            mse_weight: MSEæŸå¤±åˆå§‹æƒé‡
            ssim_weight: SSIMæŸå¤±åˆå§‹æƒé‡
            adaptive_patience: è‡ªé€‚åº”è°ƒæ•´çš„è€å¿ƒå€¼
            adaptive_factor: è‡ªé€‚åº”è°ƒæ•´å› å­
            verbose: æ˜¯å¦æ‰“å°è°ƒæ•´ä¿¡æ¯
        """
        self.total_epochs = total_epochs
        self.adaptive_patience = adaptive_patience
        self.adaptive_factor = adaptive_factor
        self.verbose = verbose
        
        # å½“å‰æƒé‡ - åªæ”¯æŒMSEå’ŒSSIM
        self.current_weights = {
            'mse': mse_weight,
            'ssim': ssim_weight
        }
        
        # è‡ªé€‚åº”è°ƒæ•´ç›¸å…³
        self.best_metric = float('inf')
        self.patience_counter = 0
        self.metric_history = []
        
        if self.verbose:
            print("ğŸ¯ å¾®è°ƒä¸“ç”¨æŸå¤±æƒé‡è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"   åˆå§‹æƒé‡: MSE={mse_weight:.3f}, SSIM={ssim_weight:.3f}")
    

    
    def get_current_weights(self) -> Dict[str, float]:
        """è·å–å½“å‰æƒé‡"""
        return self.current_weights.copy()
    
    def step(self, epoch: int, validation_metric: Optional[float] = None) -> Dict[str, float]:
        """
        æ›´æ–°æƒé‡ - åŸºäºRMSEåŠ¨æ€è°ƒæ•´MSEå’ŒSSIMæƒé‡
        
        Args:
            epoch: å½“å‰epoch (1-based)
            validation_metric: éªŒè¯æŒ‡æ ‡ (RMSEï¼Œè¶Šå°è¶Šå¥½)
            
        Returns:
            updated_weights: æ›´æ–°åçš„æƒé‡å­—å…¸
        """
        # åŸºäºRMSEè°ƒæ•´æƒé‡
        if validation_metric is not None:
            self._rmse_based_adjustment(validation_metric, epoch)
            self._adaptive_adjustment(validation_metric, epoch)
        
        # æ‰“å°æƒé‡å˜åŒ–
        if self.verbose and epoch % 10 == 0:
            self._print_current_weights(epoch, validation_metric)
        
        return self.get_current_weights()
    
    def _rmse_based_adjustment(self, current_rmse: float, epoch: int):
        """åŸºäºRMSEå€¼è°ƒæ•´MSEå’ŒSSIMæƒé‡"""
        if current_rmse > 0.15:
            # RMSEè¾ƒé«˜ï¼Œä¼˜å…ˆMSEå¿«é€Ÿæ”¶æ•›
            self.current_weights['mse'] = 1.2
            self.current_weights['ssim'] = 0.2
        elif current_rmse > 0.12:
            # RMSEä¸­ç­‰ï¼Œå¹³è¡¡ä¼˜åŒ–
            self.current_weights['mse'] = 1.0
            self.current_weights['ssim'] = 0.4
        elif current_rmse > 0.10:
            # RMSEè¾ƒå¥½ï¼Œå¢å¼ºç»“æ„ä¿æŒ
            self.current_weights['mse'] = 0.9
            self.current_weights['ssim'] = 0.5
        else:
            # RMSEå¾ˆå¥½ï¼Œé‡ç‚¹ä¿æŒè´¨é‡
            self.current_weights['mse'] = 0.8
            self.current_weights['ssim'] = 0.6
    
    def _adaptive_adjustment(self, validation_metric: float, epoch: int):
        """åŸºäºéªŒè¯æŒ‡æ ‡çš„è‡ªé€‚åº”è°ƒæ•´"""
        self.metric_history.append(validation_metric)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ”¹å–„
        if validation_metric < self.best_metric:
            self.best_metric = validation_metric
            self.patience_counter = 0
        else:
            self.patience_counter += 1
        
        # å¦‚æœè¿ç»­å¤šä¸ªepochæ²¡æœ‰æ”¹å–„ï¼Œå¾®è°ƒæƒé‡
        if self.patience_counter >= self.adaptive_patience:
            self._perform_adaptive_adjustment(epoch)
            self.patience_counter = 0
    
    def _perform_adaptive_adjustment(self, epoch: int):
        """æ‰§è¡Œè‡ªé€‚åº”æƒé‡è°ƒæ•´ - åªé’ˆå¯¹MSEå’ŒSSIM"""
        if self.verbose:
            print(f"\nğŸ”„ Epoch {epoch}: æ‰§è¡Œè‡ªé€‚åº”æƒé‡è°ƒæ•´")
        
        # ç­–ç•¥ï¼šå½“æ€§èƒ½åœæ»æ—¶ï¼Œé€‚åº¦å¢å¼ºSSIMæƒé‡ï¼Œé™ä½MSEæƒé‡
        old_mse = self.current_weights["mse"]
        old_ssim = self.current_weights["ssim"]
        
        # é™ä½MSEæƒé‡ï¼Œé¿å…è¿‡æ‹Ÿåˆ
        self.current_weights["mse"] = max(old_mse * self.adaptive_factor, 0.5)
        
        # å¢å¼ºSSIMæƒé‡ï¼Œæ”¹å–„ç»“æ„ç›¸ä¼¼æ€§
        self.current_weights["ssim"] = min(old_ssim * 1.2, 0.8)
        
        if self.verbose:
            print(f"   MSEæƒé‡: {old_mse:.3f} â†’ {self.current_weights['mse']:.3f}")
            print(f"   SSIMæƒé‡: {old_ssim:.3f} â†’ {self.current_weights['ssim']:.3f}")
    
    def _print_current_weights(self, epoch: int, rmse: Optional[float] = None):
        """æ‰“å°å½“å‰æƒé‡"""
        rmse_str = f" (RMSE: {rmse:.4f})" if rmse is not None else ""
        print(f"\nğŸ“Š Epoch {epoch}{rmse_str} å½“å‰æŸå¤±æƒé‡:")
        print(f"   MSE: {self.current_weights['mse']:.4f}")
        print(f"   SSIM: {self.current_weights['ssim']:.4f}")
    
    def get_schedule_summary(self) -> str:
        """è·å–è°ƒåº¦å™¨æ‘˜è¦ä¿¡æ¯"""
        summary = "Fine-Tuning Loss Weight Scheduler Summary:\n"
        summary += f"Total Epochs: {self.total_epochs}\n"
        summary += f"Adaptive Patience: {self.adaptive_patience}\n"
        summary += f"Current Weights: MSE={self.current_weights['mse']:.3f}, SSIM={self.current_weights['ssim']:.3f}\n"
        summary += f"Best RMSE: {self.best_metric:.4f}\n"
        
        return summary
    
    def save_state(self, filepath: str):
        """ä¿å­˜è°ƒåº¦å™¨çŠ¶æ€"""
        state = {
            'current_weights': self.current_weights,
            'best_metric': self.best_metric,
            'patience_counter': self.patience_counter,
            'metric_history': self.metric_history
        }
        torch.save(state, filepath)
    
    def load_state(self, filepath: str):
        """åŠ è½½è°ƒåº¦å™¨çŠ¶æ€"""
        state = torch.load(filepath, map_location='cpu')
        self.current_weights = state.get('current_weights', {})
        self.best_metric = state.get('best_metric', float('inf'))
        self.patience_counter = state.get('patience_counter', 0)
        self.metric_history = state.get('metric_history', [])


class FineTuningPresets:
    """å¾®è°ƒé˜¶æ®µçš„é¢„è®¾é…ç½®"""
    
    @staticmethod
    def get_balanced_config() -> Dict[str, float]:
        """
        å¹³è¡¡å¾®è°ƒé…ç½® - MSEå’ŒSSIMæƒé‡å¹³è¡¡
        é€‚åˆå¤§å¤šæ•°å¾®è°ƒåœºæ™¯
        """
        return {
            "mse_weight": 1.0,
            "ssim_weight": 0.3
        }
    
    @staticmethod
    def get_quality_focused_config() -> Dict[str, float]:
        """
        è´¨é‡ä¼˜å…ˆé…ç½® - æ›´æ³¨é‡SSIMç»“æ„ç›¸ä¼¼æ€§
        é€‚åˆRMSEå·²ç»è¾ƒä½ï¼Œéœ€è¦æå‡è§†è§‰è´¨é‡çš„åœºæ™¯
        """
        return {
            "mse_weight": 0.8,
            "ssim_weight": 0.5
        }
    
    @staticmethod
    def get_rmse_focused_config() -> Dict[str, float]:
        """
        RMSEä¼˜å…ˆé…ç½® - æ›´æ³¨é‡MSEåƒç´ çº§åŒ¹é…
        é€‚åˆRMSEè¿˜éœ€è¦è¿›ä¸€æ­¥é™ä½çš„åœºæ™¯
        """
        return {
            "mse_weight": 1.2,
            "ssim_weight": 0.2
        }


def create_loss_scheduler_from_config(config, total_epochs: int) -> LossWeightScheduler:
    """
    ä»é…ç½®æ–‡ä»¶åˆ›å»ºå¾®è°ƒä¸“ç”¨æŸå¤±è°ƒåº¦å™¨
    
    Args:
        config: é…ç½®å¯¹è±¡ï¼ŒåŒ…å«LOSS_SCHEDULERéƒ¨åˆ†
        total_epochs: æ€»è®­ç»ƒè½®æ•°
        
    Returns:
        LossWeightSchedulerå®ä¾‹
    """
    try:
        # ä½¿ç”¨é»˜è®¤çš„å¹³è¡¡å¾®è°ƒé…ç½®
        preset_config = FineTuningPresets.get_balanced_config()
        
        # åˆ›å»ºè°ƒåº¦å™¨ - ä½¿ç”¨ç®€åŒ–çš„é»˜è®¤é…ç½®
        scheduler = LossWeightScheduler(
            total_epochs=total_epochs,
            mse_weight=preset_config['mse_weight'],
            ssim_weight=preset_config['ssim_weight'],
            adaptive_patience=3,        # å›ºå®šä¸º3
            adaptive_factor=0.8,       # å›ºå®šä¸º0.8
            verbose=True               # å›ºå®šä¸ºTrue
        )
        
        return scheduler
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæŸå¤±è°ƒåº¦å™¨å¤±è´¥: {e}")
        # è¿”å›ä¸€ä¸ªç®€å•çš„é»˜è®¤è°ƒåº¦å™¨
        return LossWeightScheduler(
            total_epochs=total_epochs,
            mse_weight=1.0,
            ssim_weight=0.3,
            adaptive_patience=3,
            adaptive_factor=0.8,
            verbose=True
        )


if __name__ == '__main__':
    # æµ‹è¯•å¾®è°ƒä¸“ç”¨æŸå¤±è°ƒåº¦å™¨
    print("ğŸ§ª æµ‹è¯•å¾®è°ƒä¸“ç”¨æŸå¤±æƒé‡è°ƒåº¦å™¨")
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = LossWeightScheduler(
        total_epochs=50,
        mse_weight=1.0,
        ssim_weight=0.3,
        verbose=True
    )
    
    # æ¨¡æ‹Ÿå¾®è°ƒè¿‡ç¨‹
    print("\nğŸš€ æ¨¡æ‹Ÿå¾®è°ƒè¿‡ç¨‹:")
    test_epochs = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]
    test_rmse = [0.18, 0.16, 0.14, 0.13, 0.12, 0.11, 0.105, 0.102, 0.100, 0.098, 0.097]
    
    for epoch, rmse in zip(test_epochs, test_rmse):
        weights = scheduler.step(epoch, rmse)
        print(f"\nEpoch {epoch:3d} (RMSE: {rmse:.3f}):")
        print(f"  MSE:  {weights['mse']:.4f}")
        print(f"  SSIM: {weights['ssim']:.4f}")
    
    print(f"\nğŸ“Š è°ƒåº¦å™¨æ‘˜è¦:")
    print(scheduler.get_schedule_summary())
