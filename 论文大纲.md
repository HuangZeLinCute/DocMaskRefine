# ShaDocFormer: 基于双流架构的文档阴影去除深度学习模型

## 论文大纲

### 1. 摘要 (Abstract)
- 研究背景：文档图像中的阴影严重影响OCR准确性和文档可读性
- 核心贡献：提出ShaDocFormer，一种新颖的双流架构用于文档阴影去除
- 技术亮点：学习式掩码生成、Transformer注意力机制、边缘感知损失
- 应用价值：显著提升文档图像质量和后续处理任务性能

### 2. 引言 (Introduction)
#### 2.1 研究背景与动机
- 文档阴影问题的普遍性和严重性
- 传统方法的局限性：固定阈值、手工特征、泛化能力差
- 深度学习在图像恢复领域的成功应用
- 文档图像的特殊性：文字结构、边缘信息、二值化需求

#### 2.2 主要挑战
- 阴影形状和大小的多样性
- 文档内容与阴影的复杂交互
- 保持文字边缘清晰度和结构完整性
- 不同光照条件下的鲁棒性

#### 2.3 本文贡献
1. 提出ShaDocFormer：创新的双流架构文档阴影去除模型
2. 设计RestormerMask：基于Transformer的学习式掩码生成网络
3. 开发RefineUNetCoord：集成文档边界注意力的精细修复网络
4. 提出边缘感知损失函数：有效解决阴影边界黑边问题
5. 构建完整的训练和评估框架：在RDD和Kligler数据集上验证有效性

### 3. 相关工作 (Related Work)
#### 3.1 传统文档图像处理方法
- 基于阈值的阴影去除技术
- 形态学操作和滤波方法
-  Retinex理论和光照估计方法
- 局限性和适用范围分析

#### 3.2 深度学习在图像恢复中的应用
- CNN在图像去噪和增强中的进展
- 注意力机制的引入和发展
- Transformer在计算机视觉中的兴起

#### 3.3 文档图像阴影去除的深度学习方案
- 现有深度学习方法综述
- 单阶段vs多阶段方法比较
- 监督vs无监督学习策略
- 数据集和评估指标的发展

#### 3.4 与本工作的区别
- 双流架构的创新性
- Transformer在文档阴影去除中的首次应用
- 学习式掩码生成的优势
- 边缘感知损失的针对性设计

### 4. 方法 (Methodology)
#### 4.1 整体架构概述

**ShaDocFormer整体架构图：**

```
输入图像
┌─────────────────────────────────────────────────────────────────┐
│                        双流输入                                  │
│  ┌─────────────┐           ┌─────────────┐                    │
│  │ RGB图像     │           │ 灰度图像     │                    │
│  │ [B,3,H,W]   │           │ [B,1,H,W]   │                    │
│  └──────┬──────┘           └──────┬──────┘                    │
│         │                         │                           │
│         │                         │                           │
│         ▼                         ▼                           │
│  ┌─────────────────────────────────────────────────────┐      │
│  │              RefineUNetCoord (精细修复网络)          │      │
│  │  ┌─────────────┐    ┌─────────────┐    ┌──────────┐ │      │
│  │  │ CoordAttention│    │ DoubleConv  │    │   Up     │ │      │
│  │  │ 坐标注意力    │    │ 双卷积块    │    │ 上采样   │ │      │
│  │  └──────┬──────┘    └──────┬──────┘    └─────┬────┘ │      │
│  │         │                  │                 │      │      │
│  │         └──────────────────┼─────────────────┘      │      │
│  │                            │                        │      │
│  │  ┌─────────────────────────▼────────────────────────┐│      │
│  │  │              U-Net编码器-解码器                  ││      │
│  │  │  ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐  ││      │
│  │  │  │Conv↓ │ │Conv↓ │ │Conv↓ │ │Conv↑ │ │Conv↑ │  ││      │
│  │  │  │64ch  │ │128ch │ │256ch │ │128ch │ │64ch  │  ││      │
│  │  │  └──────┘ └──────┘ └──────┘ └──────┘ └──────┘  ││      │
│  │  │        ↓跳跃连接              ↑跳跃连接        ││      │
│  │  └──────────────────────────────────────────────────┘│      │
│  └──────────────────────────┬────────────────────────────┘      │
│                              │                                 │
│                              ▼                                 │
│  ┌─────────────────────────────────────────────────────┐      │
│  │              RestormerMask (掩码生成网络)            │      │
│  │  ┌─────────────┐    ┌─────────────┐    ┌──────────┐ │      │
│  │  │ ConvAttention│    │   GDFN      │    │LayerNorm │ │      │
│  │  │ 卷积注意力    │    │ 门控前馈    │    │ 层归一化 │ │      │
│  │  └──────┬──────┘    └──────┬──────┘    └─────┬────┘ │      │
│  │         │                  │                 │      │      │
│  │         └──────────────────┼─────────────────┘      │      │
│  │                            │                        │      │
│  │  ┌─────────────────────────▼────────────────────────┐│      │
│  │  │         4×TransformerBlockRestormer             ││      │
│  │  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐││      │
│  │  │  │ Block 1     │ │ Block 2     │ │ Block 3     │││      │
│  │  │  │ [B,64,H,W]  │ │ [B,128,H,W] │ │ [B,256,H,W] │││      │
│  │  │  └─────────────┘ └─────────────┘ └─────────────┘││      │
│  │  └──────────────────────────────────────────────────┘│      │
│  └──────────┬───────────────────┬──────────────────────┘      │
│             │                   │                              │
│             ▼                   ▼                              │
│  ┌─────────────────────────────────────────────────────┐      │
│  │              双通道掩码输出 [B,2,H,W]                │      │
│  │  ┌─────────────┐           ┌─────────────┐        │      │
│  │  │ 初始掩码     │           │ 修正掩码     │        │      │
│  │  │ [前景/背景]  │           │ [优化结果]   │        │      │
│  │  └──────┬──────┘           └──────┬──────┘        │      │
│  │         │                         │               │      │
│  │         └───────────┬─────────────┘               │      │
│  │                     ▼                               │      │
│  │  ┌────────────────────────────────────────────────────┐│      │
│  │  │              掩码融合与选择                        ││      │
│  │  │  最终掩码 = α×初始掩码 + (1-α)×修正掩码           ││      │
│  │  └────────────────────┬──────────────────────────────┘│      │
│  └───────────────────────┼───────────────────────────────┘      │
└──────────────────────────┼──────────────────────────────────────┘
                           │
                           ▼
              ┌─────────────────────────────────────┐
              │        特征拼接与融合                │
              │  输入：RGB图[3ch] + 掩码[2ch] = [5ch] │
              │  输出：融合特征图 [B,5,H,W]           │
              └────────────────┬────────────────────┘
                               │
                               ▼
              ┌─────────────────────────────────────┐
              │        精细修复与重建              │
              │  │  RefineUNetCoord处理5通道输入        │
│  │  - 文档边界注意力模块（启用）        │
│  │  - BlackEdgeSuppressor（未启用）     │
│  │  - BackgroundReference（未启用）     │
│  │  输出：修复后的RGB图像 [B,3,H,W]     │    │
              └────────────────┬────────────────────┘
                               │
                               ▼
              ┌─────────────────────────────────────┐
              │        最终输出图像                │
              │  去除阴影的清晰文档图像             │
              │  保持文字边缘和结构完整性           │
              └─────────────────────────────────────┘
```

**核心架构特点：**

1. **双流设计哲学**：
   - 灰度图像 → RestormerMask → 双通道掩码
   - RGB图像 + 掩码 → RefineUNetCoord → 修复图像

2. **RestormerMask网络**：
   - 4层TransformerBlockRestormer堆叠
   - ConvAttention：CvT风格的卷积投影注意力
   - GDFN：门控深度卷积前馈网络
   - 输出双通道掩码（初始掩码 + 修正掩码）

3. **RefineUNetCoord网络**（基于config.yml实际配置）：
   - U-Net编码器-解码器架构
   - 文档边界注意力模块（USE_DOCUMENT_BOUNDARY: true）
   - 5通道输入：RGB[3] + 掩码[2]
   - 跳跃连接和多尺度特征融合
   - 注：BlackEdgeSuppressor和BackgroundReference模块当前未启用

4. **端到端训练**：
   - 联合优化掩码生成和图像修复
   - 边缘感知损失解决边界黑边问题
   - 复合损失函数保证重建质量

**数据流说明**：

- 输入：灰度图[B,1,H,W] + RGB图[B,3,H,W]
- 掩码生成：双通道掩码[B,2,H,W]
- 特征融合：5通道输入[B,5,H,W]
- 输出：修复RGB图[B,3,H,W]

**创新亮点**（基于config.yml实际配置）：
- 首个将Transformer用于文档阴影去除
- 学习式掩码生成替代固定阈值
- 文档边界注意力模块增强边界修复质量
- 边缘感知损失解决边界artifact
- 复合损失函数优化（8种损失项联合优化）

#### 4.2 RestormerMask：掩码生成网络
##### 4.2.1 网络结构设计
- 输入：灰度图像 [B, 1, H, W]
- 输出：双通道掩码 [B, 2, H, W]
- 整体架构：4个TransformerBlockRestormer堆叠

##### 4.2.2 ConvAttention机制
- CvT风格的卷积投影注意力
- 多头注意力设计：num_heads和温度参数
- 卷积投影vs线性投影的优势分析
- 计算复杂度和效率权衡

##### 4.2.3 GDFN前馈网络
- 门控深度卷积设计原理
- 通道扩展和压缩策略
- 与标准前馈网络的性能对比
- 参数设置和实现细节

##### 4.2.4 EdgeAwareLayer集成
- 边缘感知层的设计动机
- Sobel算子和梯度计算
- 边缘保持的重要性分析
- 与主网络的协同工作

##### 4.2.5 双掩码设计哲学
- 初始掩码：基础前景/背景分割
- 修正掩码：Transformer优化结果
- 渐进式优化策略
- 掩码融合和选择机制

#### 4.3 RefineUNetCoord：精细修复网络（基于config.yml实际配置）
##### 4.3.1 整体架构设计
- U-Net编码器-解码器架构（核心框架）
- 文档边界注意力模块（USE_DOCUMENT_BOUNDARY: true）
- 5通道输入：RGB[3] + 掩码[2]
- 跳跃连接和多尺度特征融合
- 注：BlackEdgeSuppressor和BackgroundReference模块当前未启用

##### 4.3.2 文档边界注意力机制
- 设计动机：增强文档边界区域的修复质量
- 边界检测和注意力权重计算
- 与主网络的协同工作机制
- 在整体框架中的重要作用

##### 4.3.3 多尺度特征融合
- 不同层级特征的融合策略
- 上采样方法选择：双线性vs转置卷积
- 特征对齐和尺寸匹配
- 跳跃连接的权重分配

##### 4.3.4 输入特征设计
- 5通道输入：3通道RGB + 2通道掩码
- 掩码信息的有效利用
- 特征拼接vs特征相加的选择
- 通道注意力在多模态输入中的应用

#### 4.4 主控制器：Model类
##### 4.4.1 整体流程设计
- 双输入：灰度图 + RGB图
- 单输出：修复后的RGB图
- 模块间接口设计
- 梯度流动和反向传播

##### 4.4.2 端到端训练策略
- 联合损失函数设计
- 多阶段训练方案
- 学习率调度和优化器选择
- 梯度裁剪和正则化技术

#### 4.5 损失函数设计
##### 4.5.1 复合损失函数配置
基于config.yml实际启用的损失项：
- MSE损失 (权重: 1.0)：基础重建质量保证
- SSIM损失 (权重: 0.3)：结构相似性保持
- 边缘感知损失 (权重: 0.7)：EdgeAwareLoss解决边界黑边问题
- 梯度损失 (权重: 0.4)：平滑过渡保证
- 文档边界损失 (权重: 0.9)：文档边界注意力模块优化
- 感知损失 (权重: 0.2)：VGG特征提取的多层特征融合
- 直方图损失 (权重: 0.2)：颜色分布一致性
- 透明度损失 (权重: 0.1)：渐变透明掩码处理

##### 4.5.2 边缘感知损失 (EdgeAwareLoss) 详细设计
- 设计动机：解决阴影边界黑边问题
- Sobel算子边缘检测原理
- 梯度幅值计算和MSE比较
- 在复合损失中的重要作用

##### 4.5.3 损失函数权重配置
- 各损失项权重设置的实验验证
- 针对文档阴影去除任务的优化策略
- 不同数据集上的权重调整经验

### 5. 实验设置 (Experimental Setup)
#### 5.1 数据集介绍
##### 5.1.1 RDD数据集
- 数据集规模和组成
- 图像分辨率和质量特点
- 阴影类型和分布统计
- 标注质量和一致性分析

##### 5.1.2 Kligler数据集
- 数据集来源和采集方式
- 文档类型和语言分布
- 阴影复杂度和挑战性
- 与RDD数据集的互补性

##### 5.1.3 数据预处理
- 图像尺寸归一化策略
- 灰度图转换方法
- 数据增强技术应用
- 训练/验证/测试集划分

#### 5.2 实现细节
##### 5.2.1 训练配置
- 硬件环境：GPU型号和内存要求
- 软件框架：PyTorch版本和依赖库
- 批量大小和学习率设置
- 训练周期和早停策略

##### 5.2.2 优化器选择
- Adam优化器参数设置
- 学习率调度策略
- 梯度累积和混合精度训练
- 不同模块的差异化学习率

##### 5.2.3 超参数调优
- 网络架构参数搜索
- 损失函数权重优化
- 注意力机制参数敏感性分析
- 正则化系数选择

#### 5.3 评估指标
##### 5.3.1 客观质量指标
- PSNR：峰值信噪比
- SSIM：结构相似性指数
- LPIPS：学习感知图像块相似度
- RMSE：均方根误差

##### 5.3.2 文档特定指标
- OCR准确率提升
- 文字边缘清晰度
- 二值化效果改善
- 视觉主观质量评分

##### 5.3.3 计算效率指标
- 推理时间：单张图像处理速度
- 模型大小：参数数量和存储需求
- FLOPs计算：计算复杂度分析
- 内存占用：运行时的资源消耗

### 6. 实验结果与分析 (Results and Analysis)
#### 6.1 定量结果对比
##### 6.1.1 在RDD数据集上的性能
- 与现有方法的指标对比表
- 各评估指标的详细分析
- 统计显著性检验结果
- 不同阴影类型的性能差异

##### 6.1.2 在Kligler数据集上的性能
- 跨数据集泛化能力验证
- 与RDD数据集的性能差异分析
- 不同文档类型的适应性
- 语言和文化因素的影响

##### 6.1.3 消融实验结果
- 各模块贡献度分析
- 损失函数有效性验证
- 架构设计选择的影响
- 超参数敏感性分析

#### 6.2 定性结果展示
##### 6.2.1 视觉对比图
- 输入图像、Ground Truth、方法结果对比
- 不同难度样本的处理效果
- 失败案例分析
- 边缘区域细节放大展示

##### 6.2.2 注意力可视化
- ConvAttention权重分布
- CoordAttention空间响应
- 掩码生成过程可视化
- 特征图激活分析

#### 6.3 计算效率分析
- 推理速度对比
- 模型复杂度分析
- 内存使用效率
- 实时处理可行性评估

#### 6.4 下游任务影响
##### 6.4.1 OCR性能提升
- OCR准确率前后对比
- 不同OCR引擎的适应性
- 文字检测和识别改善
- 实际应用场景测试

##### 6.4.2 二值化效果
- 传统二值化方法对比
- 自适应阈值改进
- 文档图像压缩效果
- 打印和显示质量提升

### 7. 讨论 (Discussion)
#### 7.1 方法优势总结
- 双流架构的协同效应
- Transformer注意力的有效性
- 学习式掩码的灵活性
- 边缘感知损失的针对性

#### 7.2 局限性与挑战
- 极端阴影情况的处理
- 彩色阴影的去除效果
- 手写文档的适应性
- 计算资源需求

#### 7.3 未来研究方向
- 更轻量级的架构设计
- 无监督和半监督学习
- 多模态信息融合
- 实时处理优化
- 跨域泛化能力提升

#### 7.4 社会影响考虑
- 文档数字化推广的促进作用
- 对视觉障碍人士的辅助潜力
- 历史文档保护的意义
- 隐私和安全考虑

### 8. 结论 (Conclusion)
- 主要贡献回顾
- 技术创新点总结
- 实验验证结果
- 应用前景展望
- 对领域的推动作用

### 9. 致谢 (Acknowledgments)
- 资助机构感谢
- 数据集提供者致谢
- 同行评议意见感谢
- 计算资源支持感谢

### 10. 参考文献 (References)
- 相关深度学习论文
- 文档图像处理经典文献
- 注意力机制相关研究
- 图像恢复和增强方法

### 11. 附录 (Appendix)
#### 11.1 网络架构详细参数
- 每层的具体配置
- 参数数量统计
- 计算复杂度分析

#### 11.2 训练日志和超参数
- 完整的超参数设置
- 训练过程曲线
- 收敛性分析

#### 11.3 额外实验结果
- 更多定性结果展示
- 不同初始化方式的影响
- 数据增强策略对比

#### 11.4 代码开源信息
- GitHub仓库链接
- 使用说明和依赖
- 预训练模型提供
- 复现指南

---

## 论文撰写建议

### 关键图表规划
1. **架构图**：整体双流架构和模块间连接
2. **注意力可视化**：ConvAttention和CoordAttention工作原理
3. **结果对比图**：与现有方法的视觉对比
4. **消融实验表**：各模块贡献度分析
5. **性能曲线**：训练过程和指标变化

### 创新点强调
1. 双流架构的协同设计思想
2. 学习式掩码生成的技术优势
3. 边缘感知损失的理论贡献
4. 在实际应用中的显著效果提升